
---

## **ğŸ“Œ YouTube Sentiment Analysis**
ğŸš€ **A Python project that analyzes YouTube video sentiment based on comments and video transcripts.**  
This program determines whether comments **agree or disagree** with the sentiment expressed in the video.

---

## **ğŸ“– Table of Contents**
- [ğŸŒŸ Features](#-features)
- [ğŸ›  Installation](#-installation)
- [âš™ï¸ How to Use](#-how-to-use)
- [ğŸ”„ Modifications & Customization](#-modifications--customization)
- [ğŸ’¡ Using a Different Dataset](#-using-a-different-dataset)
- [ğŸš€ Example Output](#-example-output)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ“œ License](#-license)

---

## **ğŸŒŸ Features**
âœ… Fetches **YouTube video comments** using the **YouTube Data API v3**  
âœ… Retrieves **video transcripts** (if available) to determine the videoâ€™s sentiment  
âœ… Uses a **NaÃ¯ve Bayes Classifier** trained on **Sentiment140 (Twitter-based dataset)**  
âœ… Determines whether **comments agree or disagree** with the video  
âœ… Supports fetching **top comments or latest comments**  
âœ… Handles **up to 5000 comments per video** with pagination  
âœ… Fully customizable to work with **other sentiment datasets**  

---

## **ğŸ›  Installation**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-username/youtube-sentiment-analysis.git
cd youtube-sentiment-analysis
```

### **2ï¸âƒ£ Install Required Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Install Sentiment140 Dataset (Required)**
**This repository does not include the Sentiment140 dataset.**  
You must **download it manually** or use another dataset (see [Using a Different Dataset](#-using-a-different-dataset)).  

#### **ğŸ“¥ Download Sentiment140**
1. Go to **[Sentiment140 Dataset](http://help.sentiment140.com/for-students)**
2. Download `training.1600000.processed.noemoticon.csv`
3. Rename it to **`sentiment140.csv`**
4. Move it to your project directory:
   ```
   youtube-sentiment-analysis/
   â”œâ”€â”€ youtube_comments.py
   â”œâ”€â”€ sentiment_analysis.py
   â”œâ”€â”€ sentiment140.csv  <-- âœ… Place it here!
   â”œâ”€â”€ requirements.txt
   â”œâ”€â”€ README.md
   ```

---

## **âš™ï¸ How to Use**
### **1ï¸âƒ£ Run `youtube_comments.py` to Fetch Comments & Analyze Video Sentiment**
```bash
python youtube_comments.py
```
- **Enter a YouTube Video URL**  
- **Choose how many comments to fetch**  
- **Select "top" or "latest" comments**  
- The script will:
  - Fetch comments
  - Get the video transcript (if available)
  - Analyze the **videoâ€™s sentiment**
  - Save everything to `youtube_comments.csv`

### **2ï¸âƒ£ Run `sentiment_analysis.py` to Analyze Comments**
```bash
python sentiment_analysis.py
```
- This script will:
  - Read comments from `youtube_comments.csv`
  - Predict **whether comments agree or disagree** with the video
  - Display the **final analysis results**

---

## **ğŸ”„ Modifications & Customization**
### **Change the Number of Comments Fetched**
Modify this line in `youtube_comments.py`:
```python
max_comments = 500  # Change this to any number (max 5000 recommended)
```

### **Use "Top" or "Latest" Comments by Default**
Change this line in `youtube_comments.py`:
```python
sort_by = "relevance"  # Change to "time" for latest comments
```

### **Modify Sentiment Model Parameters**
Edit `train_sentiment_model()` in `sentiment_analysis.py`:
```python
vectorizer = CountVectorizer(max_features=5000)  # Increase feature size for better accuracy
```

---

## **ğŸ’¡ Using a Different Dataset**
This project **uses Sentiment140**, but you can replace it with another sentiment dataset.

### **1ï¸âƒ£ Download a New Dataset**
Find another **labeled** dataset where text is classified as **positive/negative** (e.g., IMDB, Amazon reviews, Reddit comments).

### **2ï¸âƒ£ Modify `load_sentiment140()` in `sentiment_analysis.py`**
Replace:
```python
df = pd.read_csv("sentiment140.csv", encoding="latin1", usecols=[0, 5], names=["sentiment", "text"])
df["sentiment"] = df["sentiment"].replace({0: "neg", 4: "pos"})
```
With:
```python
df = pd.read_csv("your_new_dataset.csv")
df["sentiment"] = df["sentiment_column"].map({1: "pos", 0: "neg"})  # Modify mapping based on your dataset
```

---

## **ğŸš€ Example Output**
```
ğŸ”— Paste YouTube video URL: https://www.youtube.com/watch?v=dQw4w9WgXcQ
ğŸ”¢ Enter the number of comments to fetch (max 5000 recommended): 500
ğŸ“Œ Fetch top comments or latest comments? (Enter 'top' or 'latest'): top
âœ… YouTube comments and video sentiment saved to `youtube_comments.csv`
ğŸ¥ Video Sentiment: negative
ğŸ’¬ Total Comments Fetched: 500

ğŸ“Š **Sentiment Analysis Results:**
Total Comments Analyzed: 500
ğŸ‘ Agreeing Comments: 350 (70.00%)
ğŸ‘ Disagreeing Comments: 150 (30.00%)
```

---

## **ğŸ”§ Troubleshooting**
### **1ï¸âƒ£ `sentiment140.csv not found`**
**Solution:** Download it manually from [Sentiment140](http://help.sentiment140.com/for-students) and move it into your project directory.

### **2ï¸âƒ£ `googleapiclient.errors.HttpError: quotaExceeded`**
**Cause:** Youâ€™ve reached your **YouTube API quota limit**.  
**Solution:** Wait 24 hours or apply for a **higher quota limit** in your [Google Cloud Console](https://console.cloud.google.com/).

### **3ï¸âƒ£ `ModuleNotFoundError: No module named 'googleapiclient'`**
**Solution:** Install missing dependencies:
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ `youtube_comments.csv not found`**
**Cause:** You ran `sentiment_analysis.py` before `youtube_comments.py`.  
**Solution:** Run:
```bash
python youtube_comments.py
```
**first**, then run:
```bash
python sentiment_analysis.py
```

---
